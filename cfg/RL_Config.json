{
    "config_1": {
        "num_layers": 5,
        "learning_rate": 0.001,
        "batch_size": 32,

        "alpha": 0.001,
        "gamma": 0.9,
        "epsilon": 0.9,
        "epsilon_decay": 0.995,
        "min_epsilon": 0.01,
        "num_episodes": 1000,

        "patience": 5,
        "rl_epochs": 10,
        "retrain_patience": 10,
        "retrain_epochs": 200
    }
}